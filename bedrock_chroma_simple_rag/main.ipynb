{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f752b-0dca-4171-8b26-43920b133773",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain\n",
    "pip install -U langchain-community\n",
    "pip install -U langchain-aws\n",
    "pip install chromadb\n",
    "pip install -U langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f80db-31d4-4689-895c-811ec071b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "import langchain\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_aws.embeddings import BedrockEmbeddings\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f3692-c6e0-44f7-a36f-c1cf0e8a0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022ef26-73ce-4972-ab29-db703022bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "EMBEDDING_MODEL_ID = os.getenv(\"BEDROCK_EMBEDDING_MODEL_ID\")\n",
    "CLAUDE_MODEL_ID = os.getenv(\"BEDROCK_CLAUDE_MODEL_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4091a-fe09-4457-8230-9c366f0031a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_llm_model_and_vector_db(vector_db_name, vector_db_dir):\n",
    "    # BedrockのEmbeddingモデルとclaudeモデルを設定\n",
    "    langchain_bedrock_embedding = BedrockEmbeddings(region_name=\"ap-northeast-1\",\n",
    "                                                    model_id=EMBEDDING_MODEL_ID)\n",
    "    langchain_bedrock_chat_message = ChatBedrock(region_name=\"ap-northeast-1\",\n",
    "                                                 model_id=CLAUDE_MODEL_ID,\n",
    "                                                 provider=\"anthropic\")\n",
    "    # 空のchromaベクトルDBを作成 or 既設のchromaベクトルDBを再読み込み\n",
    "    langchain_vector_db = Chroma(collection_name=vector_db_name,\n",
    "                                 persist_directory=vector_db_dir,\n",
    "                                 embedding_function=langchain_bedrock_embedding)\n",
    "    count_for_unique_record_id = langchain_vector_db._collection.count()\n",
    "    return langchain_bedrock_embedding, langchain_bedrock_chat_message, langchain_vector_db, count_for_unique_record_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f1040-651a-4c13-939f-2ab93b9e995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunked_document_from_csv(csv_filepath, csv_col_name, chunk_size, chunk_overlap_size, chunk_separator):\n",
    "    # CSV読み込み(1行 = 1ドキュメント)\n",
    "    langchain_csv_loader = CSVLoader(file_path=csv_filepath,\n",
    "                                     source_column=csv_col_name,  # カラム名を指定 # csvの1行目はヘッダー\n",
    "                                     encoding=\"utf-8\")\n",
    "    langchain_loaded_document = langchain_csv_loader.load()\n",
    "    # チャンク分割\n",
    "    langchain_text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,  # チャンクの最大文字数\n",
    "                                                             chunk_overlap=chunk_overlap_size,  # チャンクに含める前後データの文字数\n",
    "                                                             separators=chunk_separator)  # チャンクする際の境目の対象となる文字列\n",
    "    langchain_chunked_loaded_document = langchain_text_splitter.split_documents(documents=langchain_loaded_document)\n",
    "    # チャンク分割後のドキュメントを文字列の要素の形でリスト型として保存\n",
    "    chunked_doc_list = []\n",
    "    for langchain_chunked_doc in langchain_chunked_loaded_document:\n",
    "        chunked_doc_list.append(langchain_chunked_doc.page_content)\n",
    "    return chunked_doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabd4b5-b8ca-473e-b1d1-75a2544e4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_process(chunked_doc_list, langchain_bedrock_embedding, count_for_unique_record_id):\n",
    "    unique_record_id_list = []\n",
    "    embedding_vector_list = []\n",
    "    print(datetime.datetime.now())\n",
    "    for chunked_doc in chunked_doc_list:\n",
    "        try:\n",
    "            embedding_vector = langchain_bedrock_embedding.embed_query(chunked_doc)\n",
    "            embedding_vector_list.append(embedding_vector)\n",
    "            unique_record_id = \"id{a}\".format(a=count_for_unique_record_id)\n",
    "            unique_record_id_list.append(unique_record_id)\n",
    "            count_for_unique_record_id = count_for_unique_record_id + 1\n",
    "            time.sleep(0.5)  # aws bedrockのAPIリクエスト制限に抵触しないように\n",
    "        except Exception as e:\n",
    "            print(\"要素{a}でエラーになりました。\".format(a=count_for_unique_record_id))\n",
    "    print(datetime.datetime.now())\n",
    "    return unique_record_id_list, embedding_vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4307319b-548e-4427-91f0-2ab4ad0b7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_doc_and_vector_in_vector_db(langchain_vector_db, chunked_doc_list, embedding_vector_list, unique_record_id_list):\n",
    "    langchain_vector_db._collection.add(documents=chunked_doc_list,\n",
    "                                        embeddings=embedding_vector_list,\n",
    "                                        ids=unique_record_id_list)\n",
    "    return langchain_vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa32fd-d934-4493-a8fd-7dbc71b21184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carry_out_rag_and_llm(user_prompt, langchain_vector_db, langchain_bedrock_chat_message):\n",
    "    langchain_vector_db_retriever = langchain_vector_db.as_retriever(search_kwargs={\"k\": 7})  # 類似度の高い順で7件をベクトルDBの検索結果とする\n",
    "    langchain_qa_chain = RetrievalQA.from_chain_type(llm=langchain_bedrock_chat_message,\n",
    "                                                     retriever=langchain_vector_db_retriever,\n",
    "                                                     chain_type=\"stuff\")  # ベクトルDBでの検索結果を単純にそのままプロンプトに繋げてLLMに投げる方法\n",
    "    result_from_llm = langchain_qa_chain.invoke(input={\"query\": user_prompt})\n",
    "    retriever_result_documents = langchain_vector_db_retriever.invoke(input=user_prompt)\n",
    "    return result_from_llm, retriever_result_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a909e-c8f0-4449-a34d-6ee280e31739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(user_prompt, update_vector_db_flag=False, csv_file_path=None):\n",
    "    # 1. LLMモデルとベクトルDBを設定する(ベクトルDBは新規作成 or 既存を再読み込み)\n",
    "    embed_model, message_model, vector_db, record_number = set_llm_model_and_vector_db(vector_db_name=\"hogehoge\",\n",
    "                                                                                       vector_db_dir=\"./chroma_db_for_RAG\")\n",
    "    if update_vector_db_flag == True:\n",
    "        # 2. csvファイルからドキュメントをロードしてチャンク化する\n",
    "        doc_list = get_chunked_document_from_csv(csv_filepath=csv_file_path,\n",
    "                                                 csv_col_name=\"comment\",\n",
    "                                                 chunk_size=800,\n",
    "                                                 chunk_overlap_size=50,\n",
    "                                                 chunk_separator=[\"\\n\"])\n",
    "        # 3. チャンク化したドキュメントをベクトル化する\n",
    "        id_list, vector_list = embedding_process(chunked_doc_list=doc_list,\n",
    "                                                 langchain_bedrock_embedding=embed_model,\n",
    "                                                 count_for_unique_record_id=record_number)\n",
    "        # 4. 「ドキュメント」と「ベクトル」と「一意なID」をベクトルDBに追加する(「一意なID」が重複すると上書きされる)\n",
    "        vector_db = add_doc_and_vector_in_vector_db(langchain_vector_db=vector_db,\n",
    "                                                    chunked_doc_list=doc_list,\n",
    "                                                    embedding_vector_list=vector_list,\n",
    "                                                    unique_record_id_list=id_list)\n",
    "    # 5. RAG & LLM\n",
    "    result_from_llm, retriever_result_documents = carry_out_rag_and_llm(user_prompt=user_prompt,\n",
    "                                                                        langchain_vector_db=vector_db,\n",
    "                                                                        langchain_bedrock_chat_message=message_model)\n",
    "    print(\"【LLMからの回答】\", result_from_llm[\"result\"], sep=\"\\n\")\n",
    "    print(\"*****\")\n",
    "    for i, retriever_result_document in enumerate(retriever_result_documents):\n",
    "        print(\"【ベクトルDBでの検索結果：{a}つ目】\".format(a=i+1), sep=\"\\n\")\n",
    "        print(retriever_result_document.page_content)\n",
    "        print(\"*****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac63a5-87fc-4b29-bfed-f6206c5ec970",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(user_prompt=\"Netflixを解約する理由は？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b52ca-9fbf-4b0e-a757-a4b068a70710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_csv_file_path = \"/home/ec2-user/hogehoge.csv\"\n",
    "# main(user_prompt=\"Netflixを解約する理由は？\",\n",
    "#      update_vector_db_flag=True,\n",
    "#      csv_file_path=document_csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28eb499-3741-4de1-9f59-52fd669db284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tanaka_kernel(Python3-11)",
   "language": "python",
   "name": "tanaka_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
