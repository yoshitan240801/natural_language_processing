{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubHqI3wHh942"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFVzlNdwjNPH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jbqe6lZAP7J"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxOcS4Qsnr82"
   },
   "source": [
    "**テキスト生成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJG6atNBjO3e"
   },
   "outputs": [],
   "source": [
    "# rinna社の事前学習済みGPTモデルのチェックポイント名\n",
    "model_checkpoint = \"rinna/japanese-gpt2-medium\"\n",
    "# rinna社の事前学習済みGPTモデルのトークナイザーを取得\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokenizer.get_vocab()))  # トークナイザーの辞書の単語数\n",
    "print(tokenizer.pad_token_id)  # トークナイザーの辞書に登録されているpaddingのID\n",
    "print(tokenizer.bos_token_id)  # トークナイザーの辞書に登録されているBoS(Begin of Sentence)のID\n",
    "print(tokenizer.eos_token_id)  # トークナイザーの辞書に登録されているEoS(End of Sentence)のID\n",
    "print(tokenizer.unk_token_id)  # トークナイザーの辞書に登録されている不明語のID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igUsVArQBgLf"
   },
   "outputs": [],
   "source": [
    "text_input_data = \"お勧めのライフハックと言えば、\"\n",
    "tokenized_text_input_data = tokenizer(text_input_data,\n",
    "                                      padding=True,\n",
    "                                      truncation=True,\n",
    "                                      add_special_tokens=False,\n",
    "                                      return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCYyphXYJJdo"
   },
   "outputs": [],
   "source": [
    "print(tokenized_text_input_data.data)  # トークン化した文章データの中身"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gq4qufR7MebC"
   },
   "outputs": [],
   "source": [
    "# rinna社の事前学習済みGPTモデルのニューラルネットワークモデルを取得\n",
    "nn_model = transformers.AutoModelForCausalLM.from_pretrained(model_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDhv7wwRMtKq"
   },
   "outputs": [],
   "source": [
    "# テキスト生成\n",
    "with torch.no_grad():\n",
    "    nn_model.eval()\n",
    "    output = nn_model.generate(input_ids=tokenized_text_input_data.data[\"input_ids\"],  # インプットとなるトークンを2次元行列で格納\n",
    "                               attention_mask=tokenized_text_input_data.data[\"attention_mask\"],  # アテンションマスクを2次元行列で格納\n",
    "                               max_length=100,  # 生成されるテキストの最大長\n",
    "                               min_length=20,  # 生成されるテキストの最小長\n",
    "                               num_return_sequences=3,  # 生成される文章の数\n",
    "                               do_sample=True,  # サンプリングをするかどうか\n",
    "                               top_k=500,  # ランダムなk個の単語の中から生成される単語を選択\n",
    "                               top_p=0.95,  # 累積確率を制限する割合(0<x<1の範囲)\n",
    "                               pad_token_id=tokenizer.pad_token_id,  # パディングのトークンを指定\n",
    "                               bos_token_id=tokenizer.bos_token_id,  # BoS(Begin of Sentence)のトークンを指定\n",
    "                               eos_token_id=tokenizer.eos_token_id,  # EoS(End of Sentence)のトークンを指定\n",
    "                               bad_words_ids=[[tokenizer.unk_token_id]])  # 生成しない単語のトークンをリスト of リストの形で指定\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMdp8a8RYSkJ"
   },
   "outputs": [],
   "source": [
    "generated_text_dict = {}\n",
    "for i in range(output.shape[0]):\n",
    "    output_generated_text = tokenizer.convert_ids_to_tokens(output[i].detach().cpu().numpy())  # テンソルから微分計算を外して、cpu処理にして、numpyへ変換(※1次元ベクトルである事)した後に、id2value変換\n",
    "    print(output_generated_text)\n",
    "    print(type(output_generated_text))\n",
    "    generated_text = \"\".join(output_generated_text)\n",
    "    generated_text = generated_text.replace(\"▁\", \"\")\n",
    "    generated_text = generated_text.replace(\"</s>\", \"\")\n",
    "    generated_text = generated_text.replace(\"[PAD]\", \"\")\n",
    "    generated_text_dict[\"{a}つ目\".format(a=i+1)] = generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqz48nLHZ0LM"
   },
   "outputs": [],
   "source": [
    "generated_text_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcS5Zpd0nxYG"
   },
   "source": [
    "**学習(Fine Tuning)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfqBMlaaqeeF"
   },
   "outputs": [],
   "source": [
    "# FineTuningのための学習データを収集\n",
    "!wget https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
    "!tar zxvf ldcc-20140209.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォルダ内のテキストファイルからタイトルを取得して、タイトルリストを作成する関数\n",
    "def get_title_list(path):\n",
    "    title_list = []\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in filenames:\n",
    "        with open(path+filename) as f:  # テキストファイルの読み込み\n",
    "            title = f.readlines()[2].strip()\n",
    "            title_list.append(title)\n",
    "    return title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmpYVUhxslQJ"
   },
   "outputs": [],
   "source": [
    "# 「it-life-hack」フォルダ内にあるテキストファイルからタイトルリストのDataFrameを作成\n",
    "df = pd.DataFrame(columns=[\"category\",\n",
    "                           \"sentence\"])\n",
    "title_list = get_title_list(\"text/it-life-hack/\")\n",
    "for title in title_list:\n",
    "    df_temp = pd.DataFrame(data={\"category\": [\"it-life-hack\"],\n",
    "                                 \"sentence\": [title]})\n",
    "    df = pd.concat(objs=[df, df_temp],\n",
    "                   ignore_index=True)\n",
    "# DataFrameの中身をシャッフル\n",
    "df = df.sample(frac=1)\n",
    "# DataFrameの中身の最初から80%を学習用、末尾から20%を検証用として、csvファイルを作成\n",
    "num = len(df)\n",
    "df.iloc[:int(num*0.8), :].to_csv(\"./train.csv\", sep=\",\", index=False)\n",
    "df.iloc[-int(num*0.2):, :].to_csv(\"./valid.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9xsCO3lIwTG"
   },
   "outputs": [],
   "source": [
    "# 学習用csvファイルをDataFrameとして取得\n",
    "train_df = pd.read_csv(\"./train.csv\", encoding=\"utf-8\")\n",
    "# 「sentence」列だけを取得して、1行1データの形のテキストファイルを新しく作成する\n",
    "for i in range(len(train_df)):\n",
    "    sentence = train_df.iloc[i, 1]  # forループで1行ずつ取得で、列は要素1でsentence列(要素0だとcategory列)\n",
    "    with open(\"./train_sentence.txt\", \"a\") as f:\n",
    "        f.write(sentence + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1V1zXqVOg-s"
   },
   "outputs": [],
   "source": [
    "# 学習データのDataset作成\n",
    "fine_tuning_train_dataset = transformers.TextDataset(tokenizer=tokenizer,\n",
    "                                                     file_path=\"./train_sentence.txt\",  # 学習データのファイルの場所\n",
    "                                                     block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlDb0AUkQ25p"
   },
   "outputs": [],
   "source": [
    "# Fine Tuningの際の学習データのマスクに関する設定\n",
    "fine_tuning_collator = transformers.DataCollatorForLanguageModeling(tokenizer=tokenizer,\n",
    "                                                                    mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_34ji_4R6tW"
   },
   "outputs": [],
   "source": [
    "# Fine Tuningに関する設定\n",
    "fine_tuning_args = transformers.TrainingArguments(output_dir=\"./generate\",  # ファイルの出力先\n",
    "                                                  overwrite_output_dir=True,  # 出力先フォルダを上書きするかどうか\n",
    "                                                  evaluation_strategy=\"epoch\",  # 評価関数を計算するタイミング\n",
    "                                                  logging_steps=100,  # ログを出すタイミング\n",
    "                                                  log_level=\"error\",  # ログレベル\n",
    "                                                  save_strategy=\"no\",  # チェックポイントを保存するタイミング\n",
    "                                                  save_total_limit=None,  # チェックポイントを保存する数\n",
    "                                                  learning_rate=2e-5,  # 学習率\n",
    "                                                  weight_decay=0.01,  # 減衰率\n",
    "                                                  per_device_train_batch_size=8,  # 学習の時のミニバッチ数\n",
    "                                                  fp16=True,  # 16ビット計算\n",
    "                                                  num_train_epochs=3)  # 学習エポック数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "executionInfo": {
     "elapsed": 2247922,
     "status": "ok",
     "timestamp": 1700462939622,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "DOoxjreIVFmQ",
    "outputId": "1cacace8-85d0-48c0-b910-1637a58a6bb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 36:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=51, training_loss=3.607676487342984, metrics={'train_runtime': 2245.8705, 'train_samples_per_second': 0.174, 'train_steps_per_second': 0.023, 'total_flos': 90548317716480.0, 'train_loss': 3.607676487342984, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine Tuning\n",
    "nn_model_trainer = transformers.Trainer(model=nn_model,\n",
    "                                        args=fine_tuning_args,\n",
    "                                        data_collator=fine_tuning_collator,\n",
    "                                        train_dataset=fine_tuning_train_dataset)\n",
    "nn_model.train()\n",
    "nn_model_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAG5S9kFguis"
   },
   "outputs": [],
   "source": [
    "# Fine Tuningの結果をセーブ\n",
    "nn_model_trainer.save_model(\"./GPT-model-after-FineTuning\")\n",
    "# Fine Tuning時の損失値や評価値などの情報をセーブ\n",
    "nn_model_trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpKeIu_pfeTc"
   },
   "source": [
    "**Fine Tuning後のテキスト生成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlkeR85rfjhR"
   },
   "outputs": [],
   "source": [
    "# rinna社のトークナイザーと、FineTuning後の事前学習済みGPTモデルのニューラルネットワークモデルをロードして取得\n",
    "model_checkpoint = \"rinna/japanese-gpt2-medium\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "nn_model_after_ft = transformers.AutoModelForCausalLM.from_pretrained(\"./GPT-model-after-FineTuning\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdmVchmQiCN_"
   },
   "outputs": [],
   "source": [
    "# テキスト生成\n",
    "text_input_data = \"お勧めのライフハックと言えば、\"\n",
    "tokenized_text_input_data = tokenizer(text_input_data,\n",
    "                                      padding=True,\n",
    "                                      truncation=True,\n",
    "                                      add_special_tokens=False,\n",
    "                                      return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    nn_model_after_ft.eval()\n",
    "    output_after_ft = nn_model_after_ft.generate(input_ids=tokenized_text_input_data.data[\"input_ids\"],  # インプットとなるトークンを2次元行列で格納\n",
    "                                                 attention_mask=tokenized_text_input_data.data[\"attention_mask\"],  # アテンションマスクを2次元行列で格納\n",
    "                                                 max_length=100,  # 生成されるテキストの最大長\n",
    "                                                 min_length=20,  # 生成されるテキストの最小長\n",
    "                                                 num_return_sequences=3,  # 生成される文章の数\n",
    "                                                 do_sample=True,  # サンプリングをするかどうか\n",
    "                                                 top_k=500,  # ランダムなk個の単語の中から生成される単語を選択\n",
    "                                                 top_p=0.95,  # 累積確率を制限する割合(0<x<1の範囲)\n",
    "                                                 pad_token_id=tokenizer.pad_token_id,  # パディングのトークンを指定\n",
    "                                                 bos_token_id=tokenizer.bos_token_id,  # BoS(Begin of Sentence)のトークンを指定\n",
    "                                                 eos_token_id=tokenizer.eos_token_id,  # EoS(End of Sentence)のトークンを指定\n",
    "                                                 bad_words_ids=[[tokenizer.unk_token_id]])  # 生成しない単語のトークンをリスト of リストの形で指定\n",
    "print(output_after_ft)\n",
    "print(output_after_ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apjT5fcviYBI"
   },
   "outputs": [],
   "source": [
    "generated_text_dict = {}\n",
    "for i in range(output_after_ft.shape[0]):\n",
    "    output_generated_text_after_ft = tokenizer.convert_ids_to_tokens(output_after_ft[i].detach().cpu().numpy())  # テンソルから微分計算を外して、cpu処理にして、numpyへ変換(※1次元ベクトルである事)した後に、id2value変換\n",
    "    print(output_generated_text_after_ft)\n",
    "    print(type(output_generated_text_after_ft))\n",
    "    generated_text = \"\".join(output_generated_text_after_ft)\n",
    "    generated_text = generated_text.replace(\"▁\", \"\")\n",
    "    generated_text = generated_text.replace(\"</s>\", \"\")\n",
    "    generated_text = generated_text.replace(\"[PAD]\", \"\")\n",
    "    generated_text_dict[\"{a}つ目\".format(a=i+1)] = generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1700468074542,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "f_-O4MFJiilO",
    "outputId": "f9da63bd-d201-47f0-96ca-28f67c8d6efc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1つ目': 'お勧めのライフハックと言えば、やはり「シェア」「モノの場所」「モバイルのスゴイところ」なのだが、これも全く使っていなかった。しかし本当に使ってみると便利でやめられなくなる。と言うか使い道がない。はてなもはてなダイアリーも便利だけど、それに比べてたしかにblogなんかにいいよね。あと気になった「今すぐ笑わせろ」企画も。はてなには本当にこんなことが得意',\n",
       " '2つ目': 'お勧めのライフハックと言えば、ios向けアプリ「夢の案内人!旅の指さし会話帳～イタリア編」が人気を集めていることを紹介しました。また、海外の“移動端末”はどうなったか?外出先で通信費用を抑える「acアダプター」とは?昨年12月の「ios7.1.1」のリリースから2年が経った現在でも、多くのユーザーから注目されているのが「“マップ移動”アプリ」',\n",
       " '3つ目': 'お勧めのライフハックと言えば、この記事を是非チェックしてみてください。古い記事を読んでほしくない人は読み飛ばしましょう!こちらの記事では、いま話題の「フリック操作」を実践するテクニックを紹介します。android端末の“見た目の美しさ”に気付いていますか?「外観をキレイに仕上げる最強アプリ」スマホのフォルダやフォルダを整理できる【知っ得!虎の巻'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1700467816773,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "MGHQgn6nx5B0",
    "outputId": "41aa2129-da1e-4e77-ef6e-74318136883f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(32000, 1024)\n",
      "    (wpe): Embedding(1024, 1024)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# モデルを表示\n",
    "print(nn_model_after_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1700467781353,
     "user": {
      "displayName": "エボルバ田中",
      "userId": "00184597541824520416"
     },
     "user_tz": -540
    },
    "id": "SdsEg_rWrGZC",
    "outputId": "66b28a4d-1e04-49a0-b9ae-5e83f6556a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336128000\n"
     ]
    }
   ],
   "source": [
    "# モデルの重み、バイアスのパラメータ数\n",
    "params = 0\n",
    "for p in nn_model_after_ft.parameters():\n",
    "    if p.requires_grad:\n",
    "        params += p.numel()\n",
    "print(params)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNI7XkSb+QucYGNIJvrdxCb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
